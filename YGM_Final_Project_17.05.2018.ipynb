{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#from supportFunctions import *\n",
    "import cPickle as pickle\n",
    "from __future__ import division\n",
    "import numpy as np\n",
    "from sklearn import tree\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sn\n",
    "import pandas as pd \n",
    "\n",
    "import scipy.cluster.hierarchy as hcluster\n",
    "from sklearn.metrics import confusion_matrix,classification_report\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extractFeatures(imageDict, dist = 5):\n",
    "    n = imageDict['numPointsInBox']\n",
    "    y = np.zeros(n)\n",
    "    \n",
    "    v1,v2,h1,h2 = imageDict['boxEdges']\n",
    "    \n",
    "    img = imageDict['image1bit']\n",
    "    featuresList = []\n",
    "    \n",
    "    fingerSet = imageDict['allFingerPoints']\n",
    "\n",
    "    c = 0 \n",
    "    for i in range(h1,h2):\n",
    "        for j in range(v1,v2):\n",
    "            x_matrix  = img[i-dist-1:i+dist , j-dist-1: j+dist]\n",
    "            xVec = x_matrix.ravel()\n",
    "            featuresList.append(xVec)\n",
    "            \n",
    "            if max(np.sum([i , j] == fingerSet, axis = 1 )) == 2:\n",
    "                y[c] = 1\n",
    "            \n",
    "            c = c + 1\n",
    "\n",
    "    X = np.vstack((featuresList))\n",
    "    return(X,y)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extractExamplesFromList(imageList, dist = 5):\n",
    "    allFeaturesList = []\n",
    "    allTargetList = []\n",
    "\n",
    "    for i, imageDict in enumerate(imageList):\n",
    "        features, target = extractFeatures(imageDict, dist = dist)\n",
    "        allFeaturesList.append(features)\n",
    "        allTargetList.append(target)\n",
    "\n",
    "    x = np.vstack((allFeaturesList))\n",
    "    y = np.hstack((allTargetList))\n",
    "    \n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Reshape_to_yHatMatrix(testingExamples, yHat):\n",
    "    number_of_images = len(testingExamples)\n",
    "    \n",
    "    image_sizes = []\n",
    "    result = []\n",
    "    c = 0 \n",
    "    for i in range(number_of_images):\n",
    "        dummy_idx = (testingExamples[i]['boxHeight'],testingExamples[i]['boxWidth'])\n",
    "        image_sizes.append(dummy_idx)\n",
    "        \n",
    "        test_im = yHat[c:(c + dummy_idx[0]*dummy_idx[1])] \n",
    "        c = c + (dummy_idx[0] * dummy_idx[1])\n",
    "        \n",
    "        test_im_matrix = test_im.reshape((dummy_idx[0], dummy_idx[1]))\n",
    "        result.append(test_im_matrix)\n",
    "    \n",
    "    return(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def remove_small_clusters(clusters, min_finger_pixel):\n",
    "    unique = set(clusters)\n",
    "    for c in unique:\n",
    "        if sum(clusters == c) < min_finger_pixel:\n",
    "            clusters = np.delete(clusters, np.where(clusters == c))\n",
    "    return(clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pickleFileName = 'fingerDataSet' + '.pickle'\n",
    "pickleFile = open(pickleFileName, 'rb')\n",
    "data = pickle.load(pickleFile)\n",
    "pickleFile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(data[51]['image'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Constructing Traning Data Set:\n",
    "trainingExampleIndices = np.arange(0,45)\n",
    "trainingExamples = [data[index] for index in trainingExampleIndices]\n",
    "trainX, trainY = extractExamplesFromList(trainingExamples, dist = 4)\n",
    "\n",
    "#Constructing Test Data Set:\n",
    "testingExampleIndices = [45, 46, 47, 48, 49, 50, 51, 52, 53]\n",
    "testingExamples = [data[index] for index in testingExampleIndices]\n",
    "testX, testY = extractExamplesFromList(testingExamples, dist = 4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf = tree.DecisionTreeClassifier(criterion = 'entropy', max_depth = 5)\n",
    "clf = clf.fit(trainX, trainY)\n",
    "yHat = clf.predict(testX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.score(testX, testY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tn, fp, fn, tp = confusion_matrix(testY, yHat).ravel()\n",
    "confusion_matrix(testY, yHat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_hat = Reshape_to_yHatMatrix(testingExamples, yHat)\n",
    "\n",
    "fig = plt.figure(0, (8, 4))\n",
    "plt.subplot(1,3,1)\n",
    "plt.imshow(Y_hat[0])\n",
    "plt.subplot(1,3,2)\n",
    "plt.imshow(Y_hat[1])\n",
    "plt.subplot(1,3,3)\n",
    "plt.imshow(Y_hat[2])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_i = np.where(Y_hat[1] == 1)[0]\n",
    "X_j = np.where(Y_hat[1] == 1)[1]\n",
    "\n",
    "data_cl  = np.column_stack((X_i, X_j))\n",
    "data_cl.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clustering\n",
    "thresh = 1.5\n",
    "clusters = hcluster.fclusterdata(data_cl, thresh, criterion=\"distance\")\n",
    "#removing small clusters (caused by false positives)\n",
    "new_clusters = remove_small_clusters(clusters,15)\n",
    "\n",
    "# plotting\n",
    "plt.scatter(*np.transpose(data_cl), c=clusters)\n",
    "plt.axis(\"equal\")\n",
    "title = \"threshold: %f, number of fingers: %d\" % (thresh, len(set(new_clusters)))\n",
    "plt.title(title)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(data_cl[:,1], data_cl[:,0], c=clusters)\n",
    "plt.axis(\"equal\")\n",
    "title = \"threshold: %f, number of fingers: %d\" % (thresh, len(set(new_clusters)))\n",
    "plt.title(title)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plots_estimates_and_actuals(testingExampleIndices,yHat, testY, data):\n",
    "    \"\"\"\n",
    "    For given yHat(estimated), testY(actual), and test examples,\n",
    "    it visualizes these in subplots.\n",
    "    \n",
    "    yHat and testY should be vectors \n",
    "    \n",
    "    \"\"\"\n",
    "    fig = plt.figure(0, (8, 6))\n",
    "    Y_hat = Reshape_to_yHatMatrix(testingExamples, yHat)\n",
    "    Y_test = Reshape_to_yHatMatrix(testingExamples, testY)\n",
    "    for i in range(len(testingExampleIndices)):\n",
    "        \n",
    "        fig.add_subplot(1,len(testingExampleIndices),i+1)\n",
    "        imageDict = data[testingExampleIndices[i]]\n",
    "        #im = makeGrayScale(imageDict)\n",
    "        im = imageDict['croppedImage']\n",
    "        im2 = im.copy()\n",
    "\n",
    "        #Paint with matches:\n",
    "        im[Y_test[i]==1] = [90]\n",
    "        im2[Y_hat[i]==1] = 0\n",
    "        \n",
    "        \n",
    "        \n",
    "        plt.imshow(im2, interpolation = 'none')\n",
    "        plt.imshow(im, interpolation = 'none', alpha = 0.3)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plots_estimates_and_actuals_YGM(testingExampleIndices,yHat, testY, data):\n",
    "    \"\"\"\n",
    "    For given yHat(estimated), testY(actual), and test examples,\n",
    "    it visualizes these in subplots.\n",
    "    \n",
    "    yHat and testY should be vectors \n",
    "    \n",
    "    \"\"\"\n",
    "    fig = plt.figure(0, (len(testingExampleIndices) + 12, len(testingExampleIndices) + 8))\n",
    "    Y_hat = Reshape_to_yHatMatrix(testingExamples, yHat)\n",
    "    Y_test = Reshape_to_yHatMatrix(testingExamples, testY)\n",
    "    for i in range(len(testingExampleIndices)):\n",
    "        \n",
    "        fig.add_subplot(1,len(testingExampleIndices),i+1)\n",
    "        imageDict = data[testingExampleIndices[i]]\n",
    "        \n",
    "        im = imageDict['croppedImage']\n",
    "        grayim = np.zeros((im.shape[0], im.shape[1], 3))\n",
    "        grayim[:,:,0] = 1./255*im\n",
    "        grayim[:,:,1] = 1./255*im\n",
    "        grayim[:,:,2] = 1./255*im\n",
    "        \n",
    "        grayim2 = grayim.copy()\n",
    "\n",
    "        #Emphasizing test and estimation comparison through pixel coloring\n",
    "        grayim[:,:,0][Y_test[i]==1] = 1\n",
    "        grayim[:,:,1][Y_test[i]==1] = 0\n",
    "        grayim[:,:,2][Y_test[i]==1] = 0\n",
    "        \n",
    "        grayim2[:,:,0][Y_hat[i]==1] = 0\n",
    "        grayim2[:,:,1][Y_hat[i]==1] = 0\n",
    "        grayim2[:,:,2][Y_hat[i]==1] = 1\n",
    "        \n",
    "        plt.imshow(grayim2, interpolation = 'none')\n",
    "        plt.imshow(grayim, interpolation = 'none', alpha = 0.3)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(testY, yHat, is_normalized = True):\n",
    "    if is_normalized == True : \n",
    "        normalized_confusion_matrix = confusion_matrix(testY, yHat)/confusion_matrix(testY, yHat).sum()\n",
    "        df_confusion_normalized = pd.DataFrame(normalized_confusion_matrix, index = [\"Classifier-0\", \"Classifier-1\"], columns = [\"True-0\", \"True-1\"])\n",
    "\n",
    "        plt.figure(figsize = (9,6))\n",
    "        sn.set(font_scale=2)\n",
    "        sn.heatmap(df_confusion_normalized, annot = True, fmt='.4g')\n",
    "        plt.show()\n",
    "    else:\n",
    "        df_confusion = pd.DataFrame(confusion_matrix(testY, yHat), index = [\"Classifier-0\", \"Classifier-1\"], columns = [\"True-0\", \"True-1\"])\n",
    "        plt.figure(figsize = (9,6))\n",
    "        sn.set(font_scale=2)\n",
    "        sn.heatmap(df_confusion, annot = True, fmt='.4g')\n",
    "        plt.show()\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(np.array(data_cl)[:,1], np.array(data_cl)[:,0] , c=clusters)\n",
    "plt.axis(\"equal\")\n",
    "title = \"threshold: %f, number of fingers: %d\" % (thresh, len(set(new_clusters)))\n",
    "plt.title(title)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plots_estimates_and_actuals(testingExampleIndices,yHat, testY, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plots_estimates_and_actuals_YGM(testingExampleIndices,yHat, testY, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(testY, yHat, is_normalized = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = LogisticRegression(random_state=0)\n",
    "classifier.fit (trainX, trainY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_hat_logi = classifier.predict(testX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_hat = Reshape_to_yHatMatrix(testingExamples, y_hat_logi)\n",
    "\n",
    "fig = plt.figure(0, (8, 4))\n",
    "plt.subplot(1,3,1)\n",
    "plt.imshow(Y_hat[0])\n",
    "plt.subplot(1,3,2)\n",
    "plt.imshow(Y_hat[1])\n",
    "plt.subplot(1,3,3)\n",
    "plt.imshow(Y_hat[2])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(testY, y_hat_logi, is_normalized = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.score(testX, testY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classifier_RF = RandomForestClassifier(n_estimators=10, criterion='entropy', random_state= 0)\n",
    "classifier_RF.fit(trainX, trainY)\n",
    "y_hat_RF = classifier_RF.predict(testX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_hat = Reshape_to_yHatMatrix(testingExamples, y_hat_RF)\n",
    "\n",
    "fig = plt.figure(0, (8, 4))\n",
    "plt.subplot(1,3,1)\n",
    "plt.imshow(Y_hat[0])\n",
    "plt.subplot(1,3,2)\n",
    "plt.imshow(Y_hat[1])\n",
    "plt.subplot(1,3,3)\n",
    "plt.imshow(Y_hat[2])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(testY, y_hat_RF, is_normalized = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_RF.score(testX, testY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(54, 27, 3))\n",
    "mlp.fit(trainX , trainY)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat_ANN = mlp.predict(testX)\n",
    "\n",
    "\n",
    "confusion_matrix(testY, y_hat_ANN)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_hat = Reshape_to_yHatMatrix(testingExamples, y_hat_ANN)\n",
    "\n",
    "fig = plt.figure(0, (8, 4))\n",
    "plt.subplot(1,3,1)\n",
    "plt.imshow(Y_hat[0])\n",
    "plt.subplot(1,3,2)\n",
    "plt.imshow(Y_hat[1])\n",
    "plt.subplot(1,3,3)\n",
    "plt.imshow(Y_hat[2])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(testY, y_hat_ANN, is_normalized = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp.score(testX, testY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classify using the raw data\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "\n",
    "pipeRAW = Pipeline([ ('mlp',MLPClassifier(hidden_layer_sizes=(54, 27, 3)))])\n",
    "\n",
    "\n",
    "\n",
    "trainingExampleIndices = np.arange(0,54)\n",
    "trainingExamples = [data[index] for index in trainingExampleIndices]\n",
    "allX, allY = extractExamplesFromList(trainingExamples, dist = 4)\n",
    "\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "print('Classification Score Without Using PCA:', cross_val_score(pipeRAW, allX, allY).mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classify using the raw data\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "\n",
    "pipeRAW = Pipeline([ ('mlp',MLPClassifier(hidden_layer_sizes=(54, 27, 3)))])\n",
    "\n",
    "\n",
    "\n",
    "trainingExampleIndices = np.arange(0,54)\n",
    "trainingExamples = [data[index] for index in trainingExampleIndices]\n",
    "allX, allY = extractExamplesFromList(trainingExamples, dist = 4)\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "print('Classification Score Without Using PCA:', cross_val_score(pipeRAW, allX, allY).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classify using the PCA-processed data\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "\n",
    "pipePCA = Pipeline([('pca', PCA(n_components=22)), ('mlp',MLPClassifier(hidden_layer_sizes=(54, 27, 3)))])\n",
    "\n",
    "\n",
    "trainingExampleIndices = np.arange(0,54)\n",
    "trainingExamples = [data[index] for index in trainingExampleIndices]\n",
    "allX, allY = extractExamplesFromList(trainingExamples, dist = 4)\n",
    "\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "\n",
    "print('Classification Score After Using PCA:',cross_val_score(pipePCA, allX, allY).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classify using the PCA-processed data\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "\n",
    "pipePCA = Pipeline([('pca', PCA(n_components=22)), ('mlp',MLPClassifier(hidden_layer_sizes=(54, 27, 3)))])\n",
    "\n",
    "\n",
    "trainingExampleIndices = np.arange(0,54)\n",
    "trainingExamples = [data[index] for index in trainingExampleIndices]\n",
    "allX, allY = extractExamplesFromList(trainingExamples, dist = 4)\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "print('Classification Score After Using PCA:',cross_val_score(pipePCA, allX, allY).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA investigation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(data[12]['image'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data[12]['image']\n",
    "C = np.cov(X)\n",
    "np.linalg.matrix_rank(C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[12]['image'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$C = L P L^T$, where L is eigenvectors matrix which is orthonormal, P is diagonal eigenvalues matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "P, L = np.linalg.eigh(C) # Eigendecomposition of C(Covariance matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.linalg.matrix_rank(L), np.linalg.matrix_rank(P)  # P is an eigenvalues array! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "P = P[::-1]\n",
    "L = L[:,::-1]\n",
    "#  np.linalg.eigh(C) this gives the ascending order, we transform it into descending order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.allclose(L.dot(np.diag(P)).dot(L.T), C)# Decomposition is successful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (8,6))\n",
    "plt.semilogy(P, '-o')\n",
    "plt.xlim([1, P.shape[0]])\n",
    "plt.xlabel('eigenvalue index')\n",
    "plt.ylabel('eigenvalue in a log scale')\n",
    "plt.title('Eigenvalues of Covariance Matrix');\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "V = L.T.dot(X) # apply projection onto eigenbases, then get the coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Re_X = L.dot(V) # Combining the eigenvectors with the coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.allclose(Re_X, X)# Full rank approximation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normed_cumsum = (P.cumsum()/P.sum())\n",
    "\n",
    "plt.figure(figsize = (10,8))\n",
    "plt.plot(normed_cumsum, '-o')\n",
    "plt.scatter(len(np.where(normed_cumsum <= 0.99)[0]), normed_cumsum[len(np.where(normed_cumsum <= 0.99)[0])], marker=(5,1,0),color='r',s=1000)\n",
    "plt.title('Cumulative Sum of the Proportion of Total Variance')\n",
    "plt.xlabel('index')\n",
    "plt.ylabel('Proportion');\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(np.where(normed_cumsum <= 0.99)[0])# To obtain target compression percentage, what k(approx. rank) sholud be"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normed_cumsum[21]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normed_cumsum[normed_cumsum <= 0.99]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(normed_cumsum[normed_cumsum <= 0.99])# That is identical above result. It is neater."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in range(len(P)):\n",
    "    ratio = sum(P[0:k+1])/ sum(P)\n",
    "    if  ratio >= 0.99:\n",
    "        break\n",
    "print(\"Pick the largest:\", k+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_list = [5, 10, 20, 30, 40, 50, 60, 70]\n",
    "for i in range(len(k_list)):\n",
    "    \n",
    "    X_tilda_k = L[:,0:k_list[i]].dot(V[0:k_list[i],:])\n",
    "    plt.figure(figsize = (6,6))\n",
    "    \n",
    "    plt.imshow(X_tilda_k)\n",
    "    plt.title('Approximated Image with k ='+' '+str(k_list[i]));\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "k_list = [5, 10, 20, 30, 40, 50, 60, 70]\n",
    "for i in range(len(k_list)):\n",
    "    X_tilda_k = L[:,0:k_list[i]].dot(V[0:k_list[i],:])\n",
    "    \n",
    "    fig = plt.figure(0, (len(k_list) + 14, len(k_list) + 10))\n",
    "    fig.add_subplot(2,len(k_list)/2,i+1)\n",
    "    \n",
    "    plt.imshow(X_tilda_k)\n",
    "    plt.title('Approximated Image with k ='+' '+str(k_list[i]));\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
